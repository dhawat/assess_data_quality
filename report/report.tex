%this will contains the latex report
\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage[allcolors=blue]{hyperref}
\usepackage{cleveref}

\newcommand\dhawat[1]{\textcolor{red}{DH: #1}}
\newcommand\mabaach[1]{\textcolor{magenta}{MA: #1}}
\newcommand\mboussaa[1]{\textcolor{blue}{MB: #1}}


\begin{document}
\section{Intoduction} % (fold)
\label{sec:Intoduction}
With any form of decision making, the quality of the decision is only as good as the data analysed, and so there is a need to ensure that the highest quality data is available for analysis. While having good levels of data quality improves analysis accuracy, having bad data quality can have a serious impact on the enterprise.
Poor data quality has a substantial impact, such as financial loss.  \href{https://www.ibm.com/blogs/journey-to-ai/}{IBM} estimate the loss of 3.1 trillion dollars annually  in USA due to poor data quality which is twice \href{https://data.worldbank.org/indicator/NY.GDP.MKTP.CD}{Canada’s GDP} in the very same year. Productivity loss, \href{https://www.forrester.com/report/Build-Trusted-Data-With-Data-Quality/RES83344}{Forrester} came up with a study that 40\% spend 1/3 of their time validating and fixing data quality issues. All of that lead to a low trust data.
Traditional data quality control methods are based on users’ experience or previously established business rules, and this
limits performance in addition to being a very time consuming process and low accuracy.

The main objective of this research was to examine how can we use
probability models and machine learning to improve indicators
of data quality in a given dataset, with no domain specific knowledge.
There was no particular regard to the domain of the dataset chosen, the main criteria for choice was the concept that bad data or outlier are rare data objects, i.e., those objects with rare combinations of feature values, compared to the majority of objects.
We built a package of Python algorithms to detect bad data present in any type of table of data. This algorithms are gathered in a Python class easy to use, and provided with detailed documentations, facilitating the comprehension and opening the door for further development of this class. The class contains test for many type of outlier (bad data) that could be found in a table of data such as: detection of repetition row, break of uniqueness rule, search for extreme values for columns with density distribution, non significant rows and columns, detection of spelling errors, and typographical error, outlier detection over rows, in each column and in each category of the columns with discreet distribution, detection of logical error between correlated columns.

This short survey is a report on the problem of data quality proposed by the company \href{ https://www.foyer.lu/en/homepage}{Foyer} during the challenges \href{https://challenge-maths.sciencesconf.org/}{\textit{mathematiques et entreprises}} organized by AMIES,  SFdS, SMF and SMAI.
In section \ref{sec:Data quality} we define the metrics describing the quality of data present in a table of data, and the difficulty arising while trying to find bad data, or to estimate the quality of the table in general. Then in section \ref{sec:Starategy used to detect bad data} we details our strategy used to deal with bad data. This section present theoretical mathematical concept behind the tests present in our Python package. In section \ref{sec:Algorithm}, we present some of the principal code used in our package described in section ref{sec:Starategy used to detect bad data}. In section \ref{sec:Experiments} we present the results of the test of our code on the table of data provides by the company \href{ https://www.foyer.lu/en/homepage}{Foyer} to test the efficiency of our methods. Finally, in section \ref{sec:Discussions}, we present the limitations of our algorithm and we propose solutions to overcome this limitations, and develope further the package.



% sectionIntoduction (end)

\section{Data quality} % (fold)
\label{sec:Data quality}



% section  Data quality (end)

\section{Starategy used to detect bad data} % (fold)
\label{sec:Starategy used to detect bad data}



% section  Starategy used to detect bad data (end)

\section{Algorithm} % (fold)
\label{sec:Algorithm}



% sectionAlgorithm (end)

\section{Experiments} % (fold)
\label{sec:Experiments}



% sectionExperiments (end)

\section{Discussions} % (fold)
\label{sec:Discussions}



% section Discussions (end)

\section*{Acknowledgments} % (fold)
\label{sec:Acknowledgments}



% sectionAcknowledgments (end)

\begin{thebibliography}{999}

    \bibitem{pan_cos_chen}
    Guansong Pang, Longbing Cao and Ling Chen:
    \emph{Outlier Detection in Complex Categorical Data
        by Modelling the Feature Value Couplings.}


\end{thebibliography}
\end{document}
